{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weather Data Analysis Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In this report, I studied the weather record in the region with label 'SBBBBBBS'. The data is from [NOAA](https://www.ncdc.noaa.gov/). It contains 12332 year measurement from 81 different stations for 6 different measurements through 1890 to 2012 in the region across North Dakota and Minnesota. The figure bellow shows the location and distribution of the stations.\n",
    "\n",
    "![region](fig/region.png)\n",
    "\n",
    "The 6 measurements are\n",
    "* **TMIN:** the daily minimum temperature.\n",
    "* **TMAX:** the daily maximum temperature.\n",
    "* **TOBS:** The average temperature for each day.\n",
    "* **PRCP:** Daily Percipitation (in mm)\n",
    "* **SNOW:** Daily snowfall (in mm)\n",
    "* **SNWD:** The depth of accumulated snow.\n",
    "\n",
    "We can get a general view of the data by plotting the mean+-std change through the year for all measurements.\n",
    "\n",
    "![mean_std1](fig/mean_std1.png)\n",
    "![mean_std2](fig/mean_std2.png)\n",
    "![mean_std3](fig/mean_std3.png)\n",
    "\n",
    "As we can see, the results make sense, e.g. temperature is higher in summer months and there's no snow in summer months. Another thing I noticed is that the plots for **PRCP** and **SNOW** are much noisier. In comparison, the plot for **SNWD** is very smooth because it's a cumulative value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA Analysis\n",
    " \n",
    "Then I tried to do PCA on the data. To get started, I plotted the percentage of variance explained vs. number of eigenvectors. This could provide us a view of how good we can approximate the data using a few eigenvectors.\n",
    "\n",
    "![var_exp1](fig/var_exp1.png)\n",
    "![var_exp2](fig/var_exp2.png)\n",
    "\n",
    "For the temperature measurements, the top 5 eigenvectors explained about 16% for **TMIN**, 18% for **TMAX** and 31% for **TOBS**. So top eigenvectors didn't explain the variance very well for temperature measurement generally. For **TMIN** and **TMAX**, the variance explained increases linearly with the number of eigenvectors. This means that the variance is uniformly ditributed among all eigenvectors, so it's hard to use few eigenvectors to approximate the data.\n",
    "\n",
    "For the rain and snow measurements, the top 5 eigenvectors explained about 8% for **PRCP**, 12% for **SNOW** and 85% for **SNWD**. So for **PRCP** and **SNOW**, top eigenvectors can't approximate the data well. But the top eigenvectors explained most variance of **SNWD**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA on SNWD\n",
    "\n",
    "From last part, we see that the top eigenvectors could explain the variance very well for **SNWD**. So I ran PCA on **SNWD** to use few eigenvectors to reconstruct the data.\n",
    "\n",
    "I first plotted the mean and top 3 eigenvectors of the **SNWD**.\n",
    "\n",
    "![snwd_mean_eig](fig/snwd_mean_eig.png)\n",
    "\n",
    "From the plot, we can explain the eigenvectors. Eigenvector 1 means more snow through Jan to May. So we can use coefficient for eig1 to control snow through Jan to May. Eigenvector 2 means less snow through Nov to Jan. So we can use coefficient for eig2 to control snow through Nov to Jan. Eigenvector 3 is more interesting with a sinusoidal shape. Large coefficient for eig3 could be explained as a delay of the snow for that year. So we can use coefficient for eig3 to control the time shift.\n",
    "\n",
    "To show the effect of eigenvector 3, I sorted the data based on the value of coefficient for eig3. The following figures are ones with smallest and largest coefficients for eig3.\n",
    "\n",
    "![recon_early](fig/recon_early.png)\n",
    "![recon_late](fig/recon_late.png)\n",
    "\n",
    "We can see that for large coefficient for eig3, the reconstructed **SNWD** (the red line) will have a later peak than those with small coefficient for eig3.\n",
    "\n",
    "To get a better understanding of the effect of different eigenvectors, I plot the reconstruction after adding mean, eig1, eig2 and eig3 with the target.\n",
    "\n",
    "![recon_best](fig/recon_best.png)\n",
    "\n",
    "After adding eig1, we adjust the value of **SNWD** through Jan to May to approximate the target. (yellow line)\n",
    "\n",
    "After adding eig2, we adjust the value of **SNWD** through Nov to Jan to approximate the target. (green line)\n",
    "\n",
    "After adding eig3, we shift the **SNWD** so it approximate the target better. (red line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Visualization of Geographical Distribution\n",
    "\n",
    "I visualized the distribution of **SNWD** on maps. To do so, I took the average of coeff1, coeff2 and coeff3 of eigenvectors of each station. Then I plotted them as a histogram on the map. e.g. the following station has a large positive coeff1, small negative coeff2 and a relatively small positive coeff3.\n",
    "\n",
    "![map_ex](fig/map_ex.png)\n",
    "\n",
    "The following figure shows the overall distribution of the **SNWD** in the region.\n",
    "\n",
    "![map_overall](fig/map_overall.png)\n",
    "\n",
    "The first thing I noticed is the existence of local similarity. e.g.\n",
    "\n",
    "![map_sim1](fig/map_sim1.png)\n",
    "![map_sim2](fig/map_sim2.png)\n",
    "\n",
    "This is a reasonable result because geographical close stations are more likely to be meteorologically similar. However, there also exists some special cases. e.g. in the following figure, all stations had similar data except one station.\n",
    "\n",
    "![map_spec](fig/map_spec.png)\n",
    "\n",
    "It's hard to explain the phenomenom based on the information we had, but some possible reasons may be different environment, elevation or even human activities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison between Temporal and Spatial Variation\n",
    "\n",
    "In this section, I studied the temporal and spatial variation of **SNWD**. In other words, is **SNWD** changing more from year to year or from station to station?\n",
    "\n",
    "To make the comparison, I first build a table of the eigenvector's coefficient where each column repesents different years of a station and each row represents different stations of a year as follow.\n",
    "\n",
    "![tbl_year_sta](fig/tbl_year_sta.png)\n",
    "\n",
    "Then I calculated the RMS of the table both after minus the mean-by-year and the mean-by-station and compare them with the original RMS. The results are shown as follow.\n",
    "\n",
    "total RMS                   =  588.823156235\n",
    "\n",
    "RMS removing mean-by-station=  566.242330464\n",
    "\n",
    "RMS removing mean-by-year   =  408.004173428\n",
    "\n",
    "We can see that the RMS after removing mean-by-year decreases much more than RMS after removing mean-by-station. Thus, we can conclude that the temporal variation is more significant than spatial variation for our data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation of PRCP between stations\n",
    "\n",
    "In this section, I tried to find correlation of **PRCP** between pairs of stations. So I calculated the statistical significance to reject the null hypothesis of the rainfall is independent between two stations for each pair of stations. We ignored those pairs of staions having too few days (< 200) that we have measurement on both staions.\n",
    "The distribution of the significance is shown as follow.\n",
    "\n",
    "![sig_dis](fig/sig_dis.png)\n",
    "\n",
    "From the distribution, we can see that most pairs has low significance so that we cannot reject the null hypothesis, but few pairs have high (about 0.4) significance. So we can conclude that there exists pairs of stations that have correlation between each other. The matrix plot of the significance pairs also support this statement. We can see the blocks on the top-left corner (these stations are highly correlated).\n",
    "\n",
    "![sig_mat](fig/sig_mat.png)\n",
    "\n",
    "Since we just arrange the stations in their name, there may exist more correlations on the matrix plot. So we run PCA on the significance matrix.\n",
    "\n",
    "![mat_pca](fig/mat_pca.png)\n",
    "\n",
    "We can see the top 10 eigenvectors explained about 3/4 of the variance, so taking the top eigenvectors is a good idea to explain the data.\n",
    "\n",
    "Then we made the matrix plot again, but we ordered the stations in order of coefficient of eigenvectors.\n",
    "\n",
    "![mat_reorder](fig/mat_reorder.png)\n",
    "\n",
    "Now we can see more correlation between stations especially for the first plot (ordered by coeff1)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
