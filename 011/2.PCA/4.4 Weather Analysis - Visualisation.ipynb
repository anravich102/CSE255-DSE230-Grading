{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "### Visualizing the distribution of the observations\n",
    "\n",
    "### Load the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "import urllib\n",
    "import math\n",
    "%pylab inline\n",
    "\n",
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark import SparkContext\n",
    "#sc.stop()\n",
    "sc = SparkContext(master=\"local[3]\",pyFiles=['lib/numpy_pack.py','lib/spark_PCA.py','lib/computeStats.py'])\n",
    "\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import *\n",
    "sqlContext = SQLContext(sc)\n",
    "\n",
    "import sys\n",
    "sys.path.append('./lib')\n",
    "\n",
    "import numpy as np\n",
    "from numpy_pack import packArray,unpackArray\n",
    "from spark_PCA import computeCov\n",
    "from computeStats import computeOverAllDist, STAT_Descriptions\n",
    "\n",
    "### Read the data frame from pickle file\n",
    "\n",
    "data_dir='../../Data/Weather'\n",
    "file_index='BBSBSBSB'\n",
    "\n",
    "from pickle import load\n",
    "\n",
    "#read statistics\n",
    "filename=data_dir+'/STAT_%s.pickle'%file_index\n",
    "STAT,STAT_Descriptions = load(open(filename,'rb'))\n",
    "print 'keys from STAT=',STAT.keys()\n",
    "\n",
    "#read data\n",
    "filename=data_dir+'/US_Weather_%s.parquet'%file_index\n",
    "\n",
    "df=sqlContext.read.parquet(filename)\n",
    "print df.count()\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STAT_Descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The data is only 12,493 rows. That's small enough to fit into a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfData = df.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The data is from weather stations in the United States. It appears that our data is from a rectangular region that covers Minnesota and a lower portion of Ontario, Canada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install geopy\n",
    "from geopy.geocoders import Nominatim\n",
    "geolocator = Nominatim()\n",
    "location = geolocator.reverse('{}, {}'.format(dfData['latitude'].median(), dfData['longitude'].median())) \n",
    "\n",
    "print('The geographical center of the stations is: {}'.format(location.address))\n",
    "\n",
    "print ('Northwest geographical corner is: {}'.format(\\\n",
    "                                                      geolocator.reverse('{}, {}'.\\\n",
    "                                                                         format(dfData['latitude'].max(), \\\n",
    "                                                                                dfData['longitude'].min())).address ))\n",
    "print ('Northeast geographical corner is: {}'.format(\\\n",
    "                                                      geolocator.reverse('{}, {}'.\\\n",
    "                                                                         format(dfData['latitude'].max(), \\\n",
    "                                                                                dfData['longitude'].max())).address ))\n",
    "print ('Southwest geographical corner is: {}'.format(\\\n",
    "                                                      geolocator.reverse('{}, {}'.\\\n",
    "                                                                         format(dfData['latitude'].min(), \\\n",
    "                                                                                dfData['longitude'].min())).address ))\n",
    "print ('Southeast geographical corner is: {}'.format(\\\n",
    "                                                      geolocator.reverse('{}, {}'.\\\n",
    "                                                                         format(dfData['latitude'].min(), \\\n",
    "                                                                                dfData['longitude'].max())).address ))\n",
    "\n",
    "from geopy import distance\n",
    "from geopy import Point\n",
    "\n",
    "p1 = Point('{}, {}'.format(dfData['latitude'].max(), dfData['longitude'].min()))\n",
    "p2 = Point('{}, {}'.format(dfData['latitude'].max(), dfData['longitude'].max()))\n",
    "eastWest = distance.distance(p1,p2).kilometers\n",
    "p1 = Point('{}, {}'.format(dfData['latitude'].min(), dfData['longitude'].min()))\n",
    "p2 = Point('{}, {}'.format(dfData['latitude'].min(), dfData['longitude'].max()))\n",
    "northSouth = distance.distance(p1,p2).kilometers\n",
    "\n",
    "print('The East-West distance is {:.3f} kilometers'.format(eastWest))\n",
    "print('The North-South distance is {:.3f} kilometers'.format(northSouth))\n",
    "print('The area covered by the data is {:,.3f} square kilometers'.format(northSouth*eastWest))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!pip install folium\n",
    "import folium\n",
    "from folium import plugins, IFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfData.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The minimum elevation is -999.9. It's a safe bet that the station is not 1000 meters below sea level. My guess is that this is a proxy meaning \"no value\". We should check this and replace -999.9 with NaN if so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(dfData['elevation']); \n",
    "plt.title('Elevation Sanity Check');\n",
    "plt.ylabel('Elevation [m]');\n",
    "plt.xlabel('Occurrence');\n",
    "plt.plot(dfData['elevation'][dfData['elevation'] == -999.9], 'r*');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## As the graph shows, there are about 3 places (red stars) where the elevation was listed as -999.9. So we should just change this to NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "elevation = dfData['elevation'].copy(deep=True)\n",
    "elevation[elevation == -999.9] = NaN\n",
    "dfData['elevation'] = elevation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfData['undefs'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfData['elevation'].hist();\n",
    "ylabel('Number of records at this elevation');\n",
    "xlabel('Elevation [m]');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now the elevation data seems reasonable. Note that the area we are surveying is at a fairly similar elevation. The mean elevation is 384 meters with a standard deviation of about 32 meters (a third of a football field). Therefore, we don't expect to see much influence from elevation. For comparison, the highest elevation in Minnesota is [Eagle Mountain](<https://en.wikipedia.org/wiki/Eagle_Mountain_%28Minnesota%29) at 701 meters. The lowest elevation is [Lake Superior](https://en.wikipedia.org/wiki/Lake_Superior) at 183 meters. The southeast section of our geographical area includes part of Lake Superior. We'll view the terrain when we plot our map in Leaflet. There are several lakes and rivers within our region. It would be interesting to compare the precipitation patterns against a similar region without as many bodies of water."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfData['elevation'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('There are {} unique stations in the data.'.format(len(dfData['station'].unique())))\n",
    "print ('The records start in the year {:.0f} and end in {:.0f}.'.format(dfData['year'].min(), dfData['year'].max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In real data, we often are confronted with missing or undefined values (NaN). Let's see the average number of undefined values per row in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfData['undefs'].hist(bins=50, normed=True);\n",
    "xlabel('Missing measurements')\n",
    "ylabel('Percent of observations');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## So the histogram shows that all rows have fewer than 50 missing values. Twenty percent of the rows have no missing values. So there should be enough data present to make some inference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The number of observations increased dramatically around 1950 and has been fairly constant since then. This is directly related to the number of stations in operation as seen from the graph below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dfData['year'].hist(bins=30);\n",
    "xlabel('Year')\n",
    "ylabel('Number of observations');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(dfData.groupby('year')['station'].count(), 'o-');\n",
    "xlabel('Year');\n",
    "ylabel('Number of active stations');\n",
    "#title('More stations came on line each year');\n",
    "plt.savefig('STATIONS.svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's check the measurements to make sure they seem to contain reasonable values. We'll just plot the histograms and make sure that they don't have too many outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STAT.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Data Sanity check\n",
    "Let's check the histograms for all of our measurements.\n",
    "'''\n",
    "sqlContext.registerDataFrameAsTable(df,'weather')\n",
    "i = 0\n",
    "\n",
    "fig, axs = plt.subplots(nrows = 2, ncols = 3, figsize=(12, 8))\n",
    "axs = axs.ravel()    # Unravel the axes list so that we can access axes in for loop\n",
    "\n",
    "for meas in STAT.keys():\n",
    "    \n",
    "    Query=\"SELECT * FROM weather WHERE measurement='%s'\"%(meas)\n",
    "    dfMeasure = sqlContext.sql(Query)\n",
    "    rows=dfMeasure.rdd.map(lambda row:unpackArray(row['vector'],np.float16)).collect()\n",
    "    D=np.vstack(rows)\n",
    "    if (meas in ['TMIN', 'TOBS', 'TMAX']):\n",
    "        D /= 10   # According to the README, these values are recorded in \"tenths of mm\"\n",
    "        \n",
    "    axs[i].hist(D[~np.isnan(D)].ravel(), bins=20, normed=True);\n",
    "    axs[i].set_title(meas + ' Histogram', fontsize=14, fontweight='bold');\n",
    "    i += 1\n",
    "\n",
    "plt.savefig('ALLMEASURES.svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## These values seem reasonable. The temperatures range is -20 to +20 C. Most days have no precipitation. The snow ranges between 0 and 1 m (40 inches). Other precipitation ranges between 0 and 40 mm (1.6 inches). These are within normal weather values through the year in the northern United States."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Select data for a particular station and measurement type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "sqlContext.registerDataFrameAsTable(df,'weather')\n",
    "Query=\"SELECT * FROM weather\\n\\tWHERE measurement='%s' and station='%s'\"%('PRCP','USC00219059')\n",
    "print Query\n",
    "df1 = sqlContext.sql(Query)\n",
    "print df1.count(),'rows'\n",
    "df1.show(2)\n",
    "rows=df1.rdd.map(lambda row:unpackArray(row['vector'],np.float16)).collect()\n",
    "T=np.vstack(rows)\n",
    "T=T/10.  # scaling to make the temperature be in centingrates\n",
    "shape(T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's take a look at how the average minimum and maximum daily temperature changes from year to year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Query=\"SELECT * FROM weather\\n\\tWHERE measurement='TMIN' ORDER BY year\"\n",
    "df1 = sqlContext.sql(Query)\n",
    "dfTMIN = df1.toPandas()\n",
    "dfTMIN['temps'] = dfTMIN['vector'].map(lambda row: unpackArray(row, np.float16)/10.0)\n",
    "dfTMIN['TMIN_mean_year'] = dfTMIN['temps'].map(np.nanmean)\n",
    "\n",
    "#plt.plot(dfTMIN['year'].unique(), dfTMIN[['year','TMIN_mean_year']].groupby('year').mean());\n",
    "plt.scatter(dfTMIN['year'], dfTMIN['TMIN_mean_year']);\n",
    "xlabel('Year');\n",
    "ylabel(r'Average ($^o$C)');\n",
    "title('Minimum Daily Temperature');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!pip install folium\n",
    "import folium\n",
    "from folium import plugins, IFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get the minimum and maximum latitude and longitudes for our geographical area\n",
    "geoArea = sqlContext.sql('select min(latitude), max(latitude), min(longitude), max(longitude) from weather').collect()[0]\n",
    "min_lat = np.floor(geoArea[0])\n",
    "max_lat = np.ceil(geoArea[1])\n",
    "min_lon = np.floor(geoArea[2])\n",
    "max_lon = np.ceil(geoArea[3])\n",
    "\n",
    "box = (min_lat, max_lat, min_lon, max_lon)\n",
    "\n",
    "center = [(min_lat+max_lat)/2, (min_lon+max_lon)/2]\n",
    "zoom = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "m2 = folium.Map(center, zoom_start=zoom, tiles='Stamen Terrain')\n",
    "\n",
    "folium.features.RectangleMarker(\n",
    "    bounds=[[min_lat,min_lon],[max_lat,max_lon]],\n",
    "    color='blue',\n",
    "    fill_color='red', fill_opacity=0.1,\n",
    "    popup='Weather Service Data').add_to(m2)\n",
    "\n",
    "\n",
    "import branca.colormap as cm\n",
    "colormap = cm.linear.Paired.scale(-4,4)\n",
    "colormap.caption = 'Average daily minimum temperature (C)'\n",
    "m2.add_child(colormap)\n",
    "\n",
    "data = dfTMIN[dfTMIN['year'] < 1950]\n",
    "#plugins.HeatMap(data[['latitude', 'longitude', 'TMIN_mean_year']].values, \\\n",
    "#               radius=10).add_to(m2)\n",
    "\n",
    "for i in range(data.shape[0]):\n",
    "    \n",
    "    folium.CircleMarker([data['latitude'].values[i], data['longitude'].values[i]], radius=20,\n",
    "                       fill_color=colormap(data['TMIN_mean_year'].values[i])).add_to(m2)\n",
    "    \n",
    "plugins.Fullscreen(\n",
    "    position='topright',\n",
    "    title='Enter fullscreen mode',\n",
    "    titleCancel='Exit fullscreen mode dear Triton',\n",
    "    forceSeparateButton=True).add_to(m2)\n",
    "\n",
    "m2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m3 = folium.Map(center, zoom_start=zoom, tiles='Stamen Terrain')\n",
    "\n",
    "folium.features.RectangleMarker(\n",
    "    bounds=[[min_lat,min_lon],[max_lat,max_lon]],\n",
    "    color='blue',\n",
    "    fill_color='red', fill_opacity=0.1,\n",
    "    popup='Weather Service Data').add_to(m3)\n",
    "\n",
    "\n",
    "import branca.colormap as cm\n",
    "colormap = cm.linear.Paired.scale(-4,4)\n",
    "colormap.caption = 'Average daily minimum temperature (C)'\n",
    "m3.add_child(colormap)\n",
    "\n",
    "data = dfTMIN[dfTMIN['year'] >= 1950]\n",
    "#plugins.HeatMap(data[['latitude', 'longitude', 'TMIN_mean_year']].values, \\\n",
    "#               radius=10).add_to(m2)\n",
    "\n",
    "for i in range(data.shape[0]):\n",
    "    \n",
    "    folium.CircleMarker([data['latitude'].values[i], data['longitude'].values[i]], radius=20,\n",
    "                       fill_color=colormap(data['TMIN_mean_year'].values[i])).add_to(m3)\n",
    "    \n",
    "plugins.Fullscreen(\n",
    "    position='topright',\n",
    "    title='Enter fullscreen mode',\n",
    "    titleCancel='Exit fullscreen mode dear Triton',\n",
    "    forceSeparateButton=True).add_to(m3)\n",
    "\n",
    "m2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Script for plotting yearly plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from YearPlotter import YearPlotter\n",
    "fig, ax = plt.subplots(figsize=(10,7));\n",
    "YP=YearPlotter()\n",
    "YP.plot(T[:2,:].transpose(),fig,ax,title='PRCP')\n",
    "#title('A sample of graphs');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Distribution of missing observations\n",
    "The distribution of missing observations is not uniform throughout the year. We visualize it below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def plot_pair(pair,func):\n",
    "    j=0\n",
    "    fig,X=subplots(1,2,figsize=(16,6))\n",
    "    axes=X.reshape(2)\n",
    "    for m in pair:\n",
    "        axis = axes[j]\n",
    "        j+=1\n",
    "        func(m,fig,axis)\n",
    "        \n",
    "def plot_valid(m,fig,axis):\n",
    "    valid_m=STAT[m]['NE']\n",
    "    YP.plot(valid_m,fig,axis,title='valid-counts '+m)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plot_pair(['TMIN','TMAX'],plot_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plot_pair(['TOBS','PRCP'],plot_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plot_pair(['SNOW', 'SNWD'],plot_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Plots of mean and std of observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def plot_mean_std(m,fig,axis):\n",
    "    mean=STAT[m]['Mean']\n",
    "    std=np.sqrt(STAT[m]['Var'])\n",
    "    graphs=np.vstack([mean-std,mean,mean+std]).transpose()\n",
    "    YP.plot(graphs,fig,axis,title='Mean+-std   '+m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plot_pair(['TMIN','TMAX'],plot_mean_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plot_pair(['TOBS','PRCP'],plot_mean_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plot_pair(['SNOW', 'SNWD'],plot_mean_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### plotting top 3 eigenvectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def plot_eigen(m,fig,axis):\n",
    "    EV=STAT[m]['eigvec']\n",
    "    YP.plot(EV[:,:3],fig,axis,title='Top Eigenvectors '+m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plot_pair(['TMIN','TMAX'],plot_eigen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plot_pair(['TOBS','PRCP'],plot_eigen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plot_pair(['SNOW', 'SNWD'],plot_eigen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Script for plotting percentage of variance explained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def pltVarExplained(j):\n",
    "    subplot(1,3,j)\n",
    "    EV=STAT[m]['eigval']\n",
    "    k=5\n",
    "    plot(([0,]+list(cumsum(EV[:k])))/sum(EV), 'o-')\n",
    "    title('Percentage of Variance Explained for '+ m)\n",
    "    ylabel('Percentage of Variance')\n",
    "    xlabel('# Eigenvector')\n",
    "    grid()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "f=plt.figure(figsize=(15,4))\n",
    "j=1\n",
    "for m in ['TMIN', 'TOBS', 'TMAX']: #,\n",
    "    pltVarExplained(j)\n",
    "    j+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "f=plt.figure(figsize=(15,4))\n",
    "j=1\n",
    "for m in ['SNOW', 'SNWD', 'PRCP']:\n",
    "    pltVarExplained(j)\n",
    "    j+=1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "#sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "190px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_position": {
    "height": "514px",
    "left": "0px",
    "right": "925px",
    "top": "107px",
    "width": "142px"
   },
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
