{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Taking station USC00278612 as an example, there are total 25 observation regarding the station, i.e. 25 years. We first visualize how the Daily Percipitation varies across different years. \n",
    "\n",
    "We focused on six measurements:\n",
    "* **TMIN, TMAX:** the daily minimum and maximum temperature.\n",
    "* **TOBS:** The average temperature for each day.\n",
    "* **PRCP:** Daily Percipitation (in mm)\n",
    "* **SNOW:** Daily snowfall (in mm)\n",
    "* **SNWD:** The depth of accumulated snow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>We start our analysis by comparing the percipitation of the most recent 10 years and the entire 25 years. From the two images shows below, we observe that the standard deviation of precipitaiton of the most recent 10 years is larger than the entire 25 years. We also find that there are some days we do not have data.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>&nbsp;<img alt=\"10year_prcp.png\" src=\"chen_figures/10year_prcp.png\" style=\"height:450px; width:600px\" /></p>\n",
    "<p>&nbsp;<img alt=\"25year_prcp.png\" src=\"chen_figures/25year_prcp.png\" style=\"height:450px; width:600px\" /></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA analysis\n",
    "\n",
    "For each of the six measurement, we compute the percentate of the variance explained as a function of the number of eigen-vectors used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Percentage of variance explained.\n",
    "![tmin_tobs_tmax.png](chen_figures/tmin_tobs_tmax.png)\n",
    "\n",
    "![eigen_snow_snwd_prcp.png](chen_figures/eigen_snow_snwd_prcp.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that for TMIN and TMAX top 5 eigen-vectors could only explain 20 variance. For observation variables like SNOW and PRCP, the top 5 eigen-vectors performs even worse in evaluation the variance. Only around 12% and 10% variance are covered respectively. On the other hand, the top 5 eigen-vectors explain more than 35% of variance in TOBS. In SNWD, variance covered by top 5 eigen-vectors exceed 80%. The first eigen-vector in SNWD is able to explain 60% of variance. Based on the above obervations, we conclude that PCA analysis might give out the best performance when further analysis is conducted with respect to the snow-depth."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of snow depth\n",
    "\n",
    "We choose to analyze the eigen-decomposition for snow-depth because the first 4 or 5 eigen-vectors explain 80% of the variance.\n",
    "\n",
    "We observe that the snow season is from mid-november to the end of march, where the middle of February marks the peak of the snow-depth.\n",
    "![SNWD_mean_std_eig_top.png](chen_figures/SNWD_mean_std_eig_top.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the eigen value plot, the variance explained by each eigenvectors reveals some hidden pattern. In top 4 eigenvectors, we see that the shape of eigenvectors 1 are most similar to the over all shape of the SNWD mean curve. The overall trend of eigenvector 2 and eigenvector 3 are similar except the month of January and Feburary. The trend of eigenvector 2 are in contrast to the trend of eigenvector 1. This is reasonable as the second principal component is the direction which maximizes variance among all directions orthogonal to the first. It also explains why there is a sharp decrease on the eig4's value during mid Nov to December. As eig4' direction is the variance-maximizing direction orthogonal to the previous 3 eigenvectors. The introduction of eig5 does not change the distribution of snow depth significantly. It is interesting to find that the trends of eig4 and eig 5 are in opposite directions. From the last figure above, seems like eig5 explains the variance missed by eig4. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the magnitude of eigenvalues is directly proportional to the amount of variation explained by a corresponding principal components. The variance explained by the $j$th principal component is simply the ratio of $j$th eigenvalue and the total variance in the original data matrix. The following cumulative variance formula is the variance explained by a principal component model constructed using factors 1 through $j$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\%CumVar_{j} = \\frac{\\sum_{i=1}^{j}\\lambda_{i}}{\\sum_{i=1}^{l}\\lambda_{i}}\\times100\\%$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![variance_residual.png](chen_figures/variance_residual.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find out the residuals change after subtracting the mean, the projection on the first eigenvector, the projection on the second eigen-vector and the projection on the third eigen-vector in sequence. We plot a grid of reconstruction plots and show as below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![residual_des.png](chen_figures/residual_des.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above figure, we find that after substracting the first three eigen-vector, the residual has dropped to around 12%-15%. This indicate that using the first 3 eigen-vectors and mean value could recontruct the original dataset pretty well"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### What is the distribution of the residuals and the coefficients?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To answer this question, we extract all of the values of 'res_3' which is the residual variance after the the Mean and the first two Eigen-vectors have been subtracted out. We rely here on the fact that 'df3' is already sorted according to 'res_3'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><img alt=\"res_3_coeff_3.png\" src=\"chen_figures/res_3_coeff_3.png\" style=\"height:300px; width:800px\" /></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above image, we observe that the distribution of residual and coefficient is not uniform. The first few eigen vectors have negative coefficency. And as the SNWD could be well reconstructed by the first few eigen vectors. The cumulative distribution of res_3 increases rapidly at beginning as shown in left figure. Then the cumulative distribution reach a plateau area corresponding to eigenvectors with small coefficiency. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10year_prcp.png            avg_1_geo.png\r\n",
      "25year_prcp.png            coeff_3.png\r\n",
      "Residual_of_variance.png   eigen_snow_snwd_prcp.png\r\n",
      "SNWD_mean_std.png          map_5.png\r\n",
      "SNWD_mean_std_eig.png      res_3.png\r\n",
      "SNWD_mean_std_eig_top.png  res_3_coeff_3.png\r\n",
      "avg_1_dist.png             residual_des.png\r\n",
      "avg_1_dist_lati.png        tmin_tobs_tmax.png\r\n",
      "avg_1_dist_long.png        variance_residual.png\r\n"
     ]
    }
   ],
   "source": [
    "ls chen_figures/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Visualizing the distribution of the observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the ipyleaflet module, we visualize the distribution of the observation in map as follows\n",
    "<p><img alt=\"map_5.png\" src=\"chen_figures/map_5.png\" style=\"height:300px; width:1400px\" /></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The retangle size are determined by the maximum and minimum value of latitude and longitude in the dataset. In our dataset, there is one station in Canada, i.e the right most station. The uneven distribution of station in our dataset makes our retangle stretch and pretty wide. From the map, we observe that most of our weather stations are in states of Maine and New Hampshire. In the below image, we also visulized the relationship between geometrical variable and the average coefficiency value. From the three figures, we observe that all stations' elevation variables fall in a narrow range between 0 to 400. There is one station with elevation value equals to -1000. This might be a noise data. Most stations' longitude value fall in the range between -72 and -69. There is one outlier station present with longitude value close to -66. In the dataset, the stations' latitude values distribute evenly from 42.6 to 44.0. No apparent correlation could be found between geometrical variable and average coefficency 1 value. Along each geometrical value, the distribution of average coefficency value is pretty even. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><img alt=\"avg_1_geo.png\" src=\"chen_figures/avg_1_geo.png\" style=\"height:300px; width:1200px\" /></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze whether SNWD varies more from year to year or from place to place."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To analysis the effect of the year vs the effect of the station, we compute the RMS before and after substracting either the row or the column vector. The RMS are shown in the following code block"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* total RMS                   =  977.398862638\n",
    "* RMS removing mean-by-station=  930.247992826\n",
    "* RMS removing mean-by-year   =  496.582543868"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above block, we see that SNWD varies more from year to year. As we substract the SNWD values by the mean-by-year, the RMS values\n",
    "decrease to half of the total RMS before subtraction. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As SNWD varies more from year to year, to visualized the variation. We also visualized the mean of SNWD in the dataset after we subtract the mean of stations. We calculated the mean along both axis, i.e. by year or by station. The figures are shown as below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>&nbsp;<img alt=\"SNWD_mean_remove_station.png\" src=\"chen_figures/SNWD_mean_remove_station.png\" style=\"height:450px; width:600px\" /></p>\n",
    "<p>&nbsp;<img alt=\"SNWD_mean_remove_station_by_station.png\" src=\"chen_figures/SNWD_mean_remove_station_by_station.png\" style=\"height:450px; width:600px\" /></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above two Figures, we confirm that the mean of coefficiency varies more from year to year. For same station, the coefficency of SNWD does not vary significantly."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
