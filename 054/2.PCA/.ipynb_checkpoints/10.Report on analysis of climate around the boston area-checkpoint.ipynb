{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "# Arizona Weather Analysis\n",
    "\n",
    "This is a report on the historical analysis of weather patterns in an area that approximately overlaps the area of the City of Phoenix and Tonto National Forest.\n",
    "\n",
    "The data we will use here comes from [NOAA](https://www.ncdc.noaa.gov/). Specifically, it was downloaded from This [FTP site](ftp://ftp.ncdc.noaa.gov/pub/data/ghcn/daily/).\n",
    "\n",
    "We focused on six measurements:\n",
    "* **TMIN, TMAX:** the daily minimum and maximum temperature.\n",
    "* **TOBS:** The average temperature for each day.\n",
    "* **PRCP:** Daily Percipitation (in mm)\n",
    "* **SNOW:** Daily snowfall (in mm)\n",
    "* **SNWD:** The depth of accumulated snow.\n",
    "\n",
    "## Sanity-check: comparison with outside sources\n",
    "\n",
    "<p>We start by comparing some of the general statistics with graphs that we obtained from a site called <a href=\"http://www.usclimatedata.com/climate/boston/massachusetts/united-states/usma0046\" target=\"_blank\">US Climate Data</a> The graph below shows the daily minimum and maximum temperatures for each month, as well as the total precipitation for each month.</p>\n",
    "\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "<p><img alt=\"us_climate_arizona.png\" src=\"r_figures/us_climate_arizona.png\" style=\"height:500px; width:500px\"/></p>\n",
    "\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "<p>We see that the min and max daily&nbsp;temperature agree with the ones we got from our data, once we translate Fahrenheit to Centigrade.</p>\n",
    "\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "<p><img alt=\"MIN_MAX_T_AZ.png\" src=\"r_figures/MIN_MAX_T_AZ.png\" style=\"height:300px; width:800px\" /></p>\n",
    "\n",
    "<p>To compare the precipitation&nbsp;we need to translate millimeter/day to inches/month. According to our analysis the average rainfall is 0.8 mm/day which translates to about 0.94 Inches&nbsp;per month. According to US-Climate-Data the average rainfall is closer to 0.8 inch per month. However, we can still see an agreement on the distribution of the precipitation.</p>\n",
    "\n",
    "<p>&nbsp;<img alt=\"PRCP_AZ.png\" src=\"r_figures/PRCP_AZ.png\" style=\"height:450px; width:600px\" /></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "## PCA analysis\n",
    "\n",
    "We compute the percentate of the variance explained as a function of the number of eigen-vectors used for all of the six measurements.\n",
    "\n",
    "### Percentage of variance explained.\n",
    "![VarExplained1.png](r_figures/PVE1.png)\n",
    "We see that the top 5 eigen-vectors explain 48% of variance for TMIN, 60% for TOBS and 46% for TMAX.\n",
    "\n",
    "We can conclude that all of these 3 measurements are well-explained by the top 5 eigenvectors, and especially we can see that the first eigen-vector explains 38%, 52%, and 35% of the variance by itself. And we also note that TOBS is best explained among these three.\n",
    "\n",
    "![VarExplained2.png](r_figures/PVE2.png)\n",
    "\n",
    "The top 5 eigenvectors graps a little variance on PRCP and SNOW, they explain 8% of the variance for PRCP and 17% for SNOW. However, the top 5 eigenvectors explain 86% of the variance for SNWD. This means that these top 5 eigenvectors can get most of the variation in the snow signals. Based on that we can focus more on PCA analysis for snow-depth.\n",
    "\n",
    "Why SNWD would be less noisy than SNOW? That is because SNWD is a decaying integral of SNOW and, as such, varies less between days and between the same date on diffferent years.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "## Analysis of snow depth\n",
    "\n",
    "In last part, we note that SNWD is well-explained by its top 5 eigenvectors. So in this part, we will focus on PCA analysis for snow depth. We choose to analyze the eigen-decomposition for snow-depth because the first 4 eigen-vectors explain 84% of the variance, which is very close to the 86% of variance explained by the top 5 eigen-vectors.\n",
    "\n",
    "First, we graph the mean and the top 4 eigen-vectors.\n",
    "\n",
    "We observe that the snow season is from mid-november to the mid-April, where the middle of January marks the peak of the snow-depth.\n",
    "![SNWD_mean_eigs.png](r_figures/SNWD_M_E_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "Note that the first eigen-function(eig1) has a very similar shape with the mean function but the mean graph goes sharp while eig1 graph goes smooth. We can interprete this as the eig1 represents the overall amount of snow during the year but extra information can be brought by other eigens. \n",
    "\n",
    "**eig2,eig3 and eig4** are all oscilate between positive and negative values. In other words, they correspond to changing the distribution of the snow depth over the winter months. This makes sense.\n",
    "\n",
    "So we can be interpreted as follows:\n",
    "* **eig2:** more snow in mid-Jan to end Feb, less snow in Nov to early-Jan.\n",
    "* **eig3:** less snow in mid-Feb to early Mar, more snow in Mid-Mar to early-Feb\n",
    "* **eig4:** more snow in mid-Dec, less snow in end-Dec, more snow in early-Jan to Feb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "### Reconstruction: problems and interpretation\n",
    "\n",
    "#### The best reconstruction?\n",
    "\n",
    "![reconstruction.png](r_figures/reconstruction.png)\n",
    "\n",
    "Oops, seems like what we get here is a mean value that seems like 0 all the way. This makes us hard to do any analysis on coefficient. How does this happen? Recall what we did before, we filter our data based on the mean of residual. Did this filter drops most of our significant data? Let's take a look at the distribution of the mean of resideuals.\n",
    "\n",
    "#### The distribution of res_mean\n",
    "\n",
    "<p><img alt=\"HIST_1.png\" src=\"r_figures/HIST_1.png\" style=\"height:300px; width:300px\"/></p>\n",
    "Above we plot a histogram of the res_mean list. Note that we can not directly plot inf, so we filter the data first and only keep those records with finite res_mean. However, we only see 200 out of 2000 records left. Therefore, 90% of our records are with infinite res_mean. It seems like PCA makes an bad prediction on our dataset. We will take a close look at coefficient to verify it.\n",
    "\n",
    "#### A close look at coef1\n",
    "<p><img alt=\"Coeff1.png\" src=\"r_figures/Coeff1.png\" style=\"height:300px; width:300px\"/></p>\n",
    "\n",
    "Again, in most records, the avg of coeff_1 is 0, this helps us verify that PCA doesn't work good on our dataset. It is probably because although top eigenvectors explained most of the variance but still other dimensions also contains important information.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "### Geographical Map\n",
    "\n",
    "In last analysis, we know that the avg of coefficient_1 is mostly 0. However, there are still several records that have large positive coefficient_1. Where they are? Let's take a look at the geographical map of our stations.\n",
    "\n",
    "![gMap.png](r_figures/gMap.png)\n",
    "\n",
    "Note that the color of circles is associated with the value of our coefficient1. We see that there is only one red dot. Where is it? Tuton national forest!!!!! This make sense since it is obvious that a forest has different weather than other areas. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Location-to-location Variation or Year-by-year Variation\n",
    "In the previous section we see the variation of Coeff1 are related . We now estimate the relative importance of location-to-location variation relative to year-by-year variation.\n",
    "\n",
    "These are measured using the fraction by which the variance is reduced when we subtract from each station/year entry the average-per-year or the average-per-station respectively. Here are the results:\n",
    "\n",
    "** coeff_1 **  \n",
    "total RMS                   =  926.100883255\n",
    "\n",
    "RMS removing mean-by-station=  704.742273774, fraction explained 24%\n",
    "\n",
    "RMS removing mean-by-year   =  518.684911496, fraction explained 45%\n",
    "\n",
    "** coeff_2 **  \n",
    "total RMS                   =  495.421568322\n",
    "\n",
    "RMS removing mean-by-station=  473.749846082, fraction explained 5%\n",
    "\n",
    "RMS removing mean-by-year   =  423.393579547, fraction explained 15%\n",
    "\n",
    "** coeff_3 **  \n",
    "total RMS                   =  259.754118839\n",
    "\n",
    "RMS removing mean-by-station=  254.886605154, fraction explained 2%\n",
    "\n",
    "RMS removing mean-by-year   =  164.234440293, fraction explained 37%\n",
    "\n",
    "We see that the variation by year explains more than the variation by station. Moreover, for coeff_1 and coeff_3, the effect of different years is pretty significant. Therefore, as what we interpreted before, the total avg amount of snow and the change of amount of snow on Feb and March, are pretty much effected by different years."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "## Analysis of Percipitation\n",
    "\n",
    "Although before we see that the top5 eigenvectors graps a littlbe variance on PRCP, but we can still graph the mean and the top 4 eigen-vectors to see what's going on.\n",
    "\n",
    "We observe that the percipitaion is maximum at around Sep and minimum at around May.\n",
    "![PRCP_M_E.png](r_figures/PRCP_M_E.png)\n",
    "\n",
    "There is not obvious agreement between the patterns of mean PRCP and each eigenvectors.\n",
    "\n",
    "So is it possible to analyze the amount of rain of the same day on different location?\n",
    "\n",
    "<p><img alt=\"cdf_rain.png\" src=\"r_figures/cdf_rain.png\" style=\"height:300px; width:500px\"/></p>\n",
    "\n",
    "Moreover, we can also take a look at the geographical map\n",
    "\n",
    "<p><img alt=\"map2.png\" src=\"r_figures/map2.png\" style=\"height:400px; width:800px\"/></p>\n",
    "\n",
    "It is likely to be hard to find correlations between the amount of rain on the same day in different stations. Because amounts of rain vary a lot between even close locations. It is more reasonable to try to compare whether or not it rained on the same day in different stations. \n",
    "\n",
    "We want to find a statistical test for rejecting the null hypothesis that says that the rainfall in the two locations is independent. First we need to find two stations that are close to each other and also have large amount of records. \n",
    "\n",
    "After we browse all the records, we found this method make sense since some stations are pretty close to each other based on residuals and also has large amount of records. For example, station USC00028348 and USC00027560. They are very close to each other and also have about 20000 records for each and remains about 15000 records after filter. \n",
    "\n",
    "After we calculate the normalized log probability for each pair of stations, we get this graph:\n",
    "\n",
    "<p><img alt=\"pnorm.png\" src=\"r_figures/pnorm.png\" style=\"height:500px; width:500px\"/></p>\n",
    "\n",
    "It looks like some of the stations in first 80 stations are highly correlated but not as obvious as the correlation in sample dataset. To further analyze the correlations, we can try SVD since we see that the top 10 eigenvectors explain about 85% of the square magnitude of the matrix.\n",
    "\n",
    "<p><img alt=\"85.png\" src=\"r_figures/85.png\" style=\"height:300px; width:400px\"/></p>\n",
    "\n",
    "Note that the top 4 eigen-vectors explain about 80% of the variance, so we can just use the top 4 eigen-vectors. Here is what we got:\n",
    "\n",
    "<p><img alt=\"4.png\" src=\"r_figures/4.png\" style=\"height:250px; width:800px\"/></p>\n",
    "\n",
    "Based on the pca decoposition, we can reorder the rows and columns of the matrix using one of the eigenvectors, which makes the grouping of the stations becomes more evident. In the first graph, we can conclude that the first 50 stations are highly correlated of each other than other stations.And also, in graph2, we find that the last 20 stations are highly-correlated. \n",
    "\n",
    "<p><img alt=\"1111.png\" src=\"r_figures/1111.png\" style=\"height:600px; width:600px\"/></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
