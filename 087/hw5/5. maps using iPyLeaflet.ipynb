{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "## iPyLeaflet\n",
    "[ipyleaflet](https://github.com/ellisonbg/ipyleaflet) is a bridge between jupyter notebooks and the [leaflet](http://leafletjs.com/)  javascript library for drawing maps.\n",
    "\n",
    "ipyleaflet comes with a few examples notebooks (this notebook was derived from one) but very little documentation,\n",
    "for more documentation read the [Leaflet IPA](http://leafletjs.com/reference.html)\n",
    "\n",
    "For installation directions, see the README on [ipyleaflet](https://github.com/ellisonbg/ipyleaflet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "from ipyleaflet import (\n",
    "    Map,\n",
    "    Marker,\n",
    "    TileLayer, ImageOverlay,\n",
    "    Polyline, Polygon, Rectangle, Circle, CircleMarker,\n",
    "    GeoJSON,\n",
    "    DrawControl\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "## Visualizing the distribution of the observations\n",
    "\n",
    "## Load the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "import urllib\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark import SparkContext\n",
    "#sc.stop()\n",
    "sc = SparkContext(master=\"local[3]\",pyFiles=['lib/numpy_pack.py','lib/computeStats.py'])\n",
    "\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import *\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./lib')\n",
    "\n",
    "import numpy as np\n",
    "from numpy_pack import packArray,unpackArray\n",
    "from computeStats import computeOverAllDist, STAT_Descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('keys from STAT=', ['TMIN', 'TOBS', 'TMAX', 'SNOW', 'SNWD', 'PRCP'])\n",
      "393\n",
      "+------------------+-------------------+------------------+---------+--------+--------+---------+-----------+-------------------+-------------------+--------------------+------------------+-----------+-----------+------+--------------------+------+\n",
      "|           coeff_1|            coeff_2|           coeff_3|elevation|   label|latitude|longitude|measurement|              res_1|              res_2|               res_3|          res_mean|    station|  total_var|undefs|              vector|  year|\n",
      "+------------------+-------------------+------------------+---------+--------+--------+---------+-----------+-------------------+-------------------+--------------------+------------------+-----------+-----------+------+--------------------+------+\n",
      "|11183.467759022718| 2476.4223902765884|385.13629972388645|   2493.3|SSSSBBSS| 33.9833|  -109.75|       SNWD| 0.0990338354005549|0.05733362444014838|0.056473987121924696|0.9695145184881402|USC00023926|1.4368523E8|     1|[C4 60 90 60 5E 6...|1979.0|\n",
      "| 7613.756556240156|-32.223273739893955|-689.6420019963615|   2493.3|SSSSBBSS| 33.9833|  -109.75|       SNWD|0.07509789847037979|0.07508996234858278| 0.06786161244122929|0.9507507796730688|USC00023926|6.6045555E7|    45|[40 4E 58 5E C4 6...|1982.0|\n",
      "+------------------+-------------------+------------------+---------+--------+--------+---------+-----------+-------------------+-------------------+--------------------+------------------+-----------+-----------+------+--------------------+------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Read the data frame from pickle file\n",
    "\n",
    "data_dir='../../Data/Weather'\n",
    "file_index='SSSSBBSS'\n",
    "meas='SNWD'\n",
    "\n",
    "from pickle import load\n",
    "\n",
    "#read statistics\n",
    "filename=data_dir+'/STAT_%s.pickle'%file_index\n",
    "STAT,STAT_Descriptions = load(open(filename,'rb'))\n",
    "print('keys from STAT=',STAT.keys())\n",
    "\n",
    "#!ls -ld $data_dir/*.parquet\n",
    "\n",
    "#read data\n",
    "filename=data_dir+'/decon_%s_%s.parquet'%(file_index,meas)\n",
    "\n",
    "df=sqlContext.read.parquet(filename)\n",
    "print(df.count())\n",
    "df.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT station, latitude,longitude,elevation,coeff_1 FROM weather\n",
      "+-----------+--------+---------+---------+------------------+\n",
      "|    station|latitude|longitude|elevation|           coeff_1|\n",
      "+-----------+--------+---------+---------+------------------+\n",
      "|USC00023926| 33.9833|  -109.75|   2493.3|11183.467759022718|\n",
      "|USC00023926| 33.9833|  -109.75|   2493.3| 7613.756556240156|\n",
      "|USC00023926| 33.9833|  -109.75|   2493.3| 9361.092523018076|\n",
      "|USC00023926| 33.9833|  -109.75|   2493.3|11159.371711325744|\n",
      "+-----------+--------+---------+---------+------------------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#extract longitude and latitude for each station\n",
    "feature='coeff_1'\n",
    "sqlContext.registerDataFrameAsTable(df,'weather')\n",
    "Query=\"SELECT station, latitude,longitude,elevation,%s FROM weather\"%feature\n",
    "print(Query)\n",
    "df1 = sqlContext.sql(Query)\n",
    "df1.show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>elevation</th>\n",
       "      <th>count(station)</th>\n",
       "      <th>avg(coeff_1)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>USC00020159</td>\n",
       "      <td>33.8492</td>\n",
       "      <td>-109.1469</td>\n",
       "      <td>2453.6</td>\n",
       "      <td>34</td>\n",
       "      <td>258.588723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>USC00020170</td>\n",
       "      <td>33.6392</td>\n",
       "      <td>-109.3278</td>\n",
       "      <td>2792.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1879.163289</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        station  latitude  longitude  elevation  count(station)  avg(coeff_1)\n",
       "22  USC00020159   33.8492  -109.1469     2453.6              34    258.588723\n",
       "20  USC00020170   33.6392  -109.3278     2792.0               1   1879.163289"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2=df1.groupby(['station','latitude','longitude','elevation']).agg({\"station\": \"count\", feature: \"mean\"})\n",
    "pdf=df2.toPandas()\n",
    "pdf.sort_values(by=['station'],inplace=True)\n",
    "pdf.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'#001cff'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#define a mapping from the range of the value to hex colors.\n",
    "from matplotlib.colors import rgb2hex\n",
    "_avg='avg(%s)'%feature\n",
    "_min=pdf[_avg].min()\n",
    "_max=pdf[_avg].max()\n",
    "_min,_max\n",
    "\n",
    "import pylab as plt\n",
    "cmap=plt.get_cmap('jet')\n",
    "def get_color(val):\n",
    "    x=(val-_min)/(_max-_min)\n",
    "    return(rgb2hex(cmap(x)[:3]))\n",
    "\n",
    "get_color(1000.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "## Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33.3767, 34.2639, -111.3447, -108.5167)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_lat,max_lat,min_long,max_long = box = ( pdf['latitude'].min(), pdf['latitude'].max(), pdf['longitude'].min() , pdf['longitude'].max()  )\n",
    "#(42.1103, 42.6167, -72.6, -70.8)\n",
    "min_lat, max_lat, min_long , max_long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "center = [(min_lat+max_lat)/2, (min_long+max_long)/2]\n",
    "zoom = 9\n",
    "\n",
    "m = Map(default_tiles=TileLayer(opacity=1.0), center=center, zoom=zoom)\n",
    "\n",
    "r = Rectangle(bounds=[[min_lat,min_long],[max_lat,max_long]], weight=5, fill_opacity=0.0)\n",
    "m += r\n",
    "\n",
    "lat_margin=(max_lat-min_lat)/4\n",
    "long_margin=(max_long-min_long)/4\n",
    "circles = []\n",
    "for index,row in pdf.iterrows():\n",
    "    _lat=row['latitude']\n",
    "    _long=row['longitude']\n",
    "    _count=row['count(station)']\n",
    "    _coef=row[_avg]\n",
    "    # taking sqrt of count so that the  area of the circle corresponds to the count\n",
    "    c = Circle(location=(_lat,_long), radius=int(100*np.sqrt(np.abs(_coef+0.0))), weight=1,\n",
    "            color='#F00', opacity=0.8, fill_opacity=0.4)\n",
    "            #fill_color=get_color(_coef))\n",
    "    circles.append(c)\n",
    "    m.add_layer(c)\n",
    "m    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "### excercises:\n",
    "* Add a legend that relates the colors to values.\n",
    "* Leaflet supports a variety of maps. See if you can get a topographical map as the background."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "pdf.plot.scatter(x='elevation',y='avg(coeff_1)');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RDD1=sc.parallelize([\"spark  basics\", \"spark big  data analysis\", \"spring\"]) \n",
    "RDD2=sc.parallelize([\"spark using pyspark\", \"big data\"])\n",
    " \n",
    "RDD1.subtract(RDD2).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "174px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
