{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "#setup\n",
    "data_dir='../../Data/Weather'\n",
    "file_index='BBBSBBBB'\n",
    "m='SNWD'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    },
    "variables": {
     "m": "SNWD"
    }
   },
   "source": [
    "## Reconstruction using top eigen-vectors\n",
    "For measurement = {{m}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Load the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Enable automiatic reload of libraries\n",
    "#%load_ext autoreload\n",
    "#%autoreload 2 # means that all modules are reloaded before every command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n",
      "    pandas as    pd \tversion=0.19.2 \trequired version>=0.19.2\n",
      "     numpy as    np \tversion=1.12.0 \trequired version>=1.12.0\n",
      "   sklearn as    sk \tversion=0.18 \trequired version>=0.18.1 ******* Update Version ******\n",
      "    urllib as urllib \tversion=1.17 \trequired version>=1.17\n",
      "   pyspark as pyspark \tversion=2.1.0+hadoop2.7 \trequired version>=2.1.0\n",
      "ipywidgets as ipywidgets \tversion=6.0.0 \trequired version>=6.0.0\n"
     ]
    }
   ],
   "source": [
    "#%matplotlib inline\n",
    "%pylab inline\n",
    "import numpy as np\n",
    "\n",
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "import sys\n",
    "sys.path.append('./lib')\n",
    "\n",
    "from numpy_pack import packArray,unpackArray\n",
    "\n",
    "from Eigen_decomp import Eigen_decomp\n",
    "from YearPlotter import YearPlotter\n",
    "from recon_plot import recon_plot\n",
    "\n",
    "from import_modules import import_modules,modules\n",
    "import_modules(modules)\n",
    "\n",
    "from ipywidgets import interactive,widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "#sc.stop()\n",
    "\n",
    "sc = SparkContext(master=\"local[3]\",pyFiles=['lib/numpy_pack.py','lib/spark_PCA.py','lib/computeStats.py','lib/recon_plot.py','lib/Eigen_decomp.py'])\n",
    "\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import *\n",
    "sqlContext = SQLContext(sc)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Read Statistics File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "[Errno 2] No such file or directory: '../../Data/Weather/STAT_BBBSBBBB.pickle'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-05cf8c47d594>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#read statistics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/STAT_%s.pickle'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mfile_index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mSTAT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mSTAT_Descriptions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mmeasurements\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSTAT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m'keys from STAT='\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmeasurements\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: [Errno 2] No such file or directory: '../../Data/Weather/STAT_BBBSBBBB.pickle'"
     ]
    }
   ],
   "source": [
    "from pickle import load\n",
    "\n",
    "#read statistics\n",
    "filename=data_dir+'/STAT_%s.pickle'%file_index\n",
    "STAT,STAT_Descriptions = load(open(filename,'rb'))\n",
    "measurements=STAT.keys()\n",
    "print 'keys from STAT=',measurements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Read data file into a spark DataFrame\n",
    "We focus on the snow-depth records, because the eigen-vectors for them make sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#read data\n",
    "filename=data_dir+'/US_Weather_%s.parquet'%file_index\n",
    "df_in=sqlContext.read.parquet(filename)\n",
    "#filter in \n",
    "df=df_in.filter(df_in.measurement==m)\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Plot Reconstructions\n",
    "\n",
    "Construct approximations of a time series using the mean and the $k$ top eigen-vectors\n",
    "First, we plot the mean and the top $k$ eigenvectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import pylab as plt\n",
    "fig,axes=plt.subplots(2,1, sharex='col', sharey='row',figsize=(10,6));\n",
    "k=3\n",
    "EigVec=np.matrix(STAT[m]['eigvec'][:,:k])\n",
    "Mean=STAT[m]['Mean']\n",
    "YearPlotter().plot(Mean,fig,axes[0],label='Mean',title=m+' Mean')\n",
    "YearPlotter().plot(EigVec,fig,axes[1],title=m+' Eigs',labels=['eig'+str(i+1) for i in range(k)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "v=[np.array(EigVec[:,i]).flatten() for i in range(np.shape(EigVec)[1])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### plot the percent of residual variance on average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#  x=0 in the graphs below correspond to the fraction of the variance explained by the mean alone\n",
    "#  x=1,2,3,... are the residuals for eig1, eig1+eig2, eig1+eig2+eig3 ...\n",
    "fig,ax=plt.subplots(1,1);\n",
    "eigvals=STAT[m]['eigval']; eigvals/=sum(eigvals); cumvar=np.cumsum(eigvals); cumvar=100*np.insert(cumvar,0,0)\n",
    "ax.plot(cumvar[:10]); \n",
    "ax.grid(); \n",
    "ax.set_ylabel('Percent of variance explained')\n",
    "ax.set_xlabel('number of eigenvectors')\n",
    "ax.set_title('Percent of variance explained');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Process whole dataframe to find best and worse residuals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Add to each row in the dataframe a residual values \n",
    "Residuals are after subtracting in sequence: the mean, the projection on the first eigen-vector the projection on the second eigen-vector etc.\n",
    "\n",
    "`decompose(row)` axtracts the series from the row, computes the residuals and constructs a new row that is reassembled into a dataframe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def decompose(row):\n",
    "    \"\"\"compute residual and coefficients for decomposition           \n",
    "\n",
    "    :param row: SparkSQL Row that contains the measurements for a particular station, year and measurement. \n",
    "    :returns: the input row with additional information from the eigen-decomposition.\n",
    "    :rtype: SparkSQL Row \n",
    "\n",
    "    Note that Decompose is designed to run inside a spark \"map()\" command.\n",
    "    Mean and v are sent to the workers as local variables of \"Decompose\"\n",
    "\n",
    "    \"\"\"\n",
    "    Series=np.array(unpackArray(row.vector,np.float16),dtype=np.float64)\n",
    "    recon=Eigen_decomp(None,Series,Mean,v);\n",
    "    total_var,residuals,reductions,coeff=recon.compute_var_explained()\n",
    "    #print coeff\n",
    "    residuals=[float(r) for r in residuals[1]]\n",
    "    coeff=[float(r) for r in coeff[1]]\n",
    "    D=row.asDict()\n",
    "    D['total_var']=float(total_var[1])\n",
    "    D['res_mean']=residuals[0]\n",
    "    for i in range(1,len(residuals)):\n",
    "        D['res_'+str(i)]=residuals[i]\n",
    "        D['coeff_'+str(i)]=coeff[i-1]\n",
    "    return Row(**D)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "rdd2=df.rdd.map(decompose)\n",
    "df2=sqlContext.createDataFrame(rdd2)\n",
    "row,=df2.take(1)\n",
    "\n",
    "#filter out vectors for which the mean is a worse approximation than zero.\n",
    "print 'before filter',df2.count()\n",
    "df3=df2.filter(df2.res_mean<1)\n",
    "print 'after filter',df3.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# Sort entries by increasing values of ers_3\n",
    "df3=df3.sort(df3.res_3,ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def plot_decomp(row,Mean,v,fig=None,ax=None,Title=None,interactive=False):\n",
    "    \"\"\"Plot a single reconstruction with an informative title\n",
    "\n",
    "    :param row: SparkSQL Row that contains the measurements for a particular station, year and measurement. \n",
    "    :param Mean: The mean vector of all measurements of a given type\n",
    "    :param v: eigen-vectors for the distribution of measurements.\n",
    "    :param fig: a matplotlib figure in which to place the plot\n",
    "    :param ax: a matplotlib axis in which to place the plot\n",
    "    :param Title: A plot title over-ride.\n",
    "    :param interactive: A flag that indicates whether or not this is an interactive plot (widget-driven)\n",
    "    :returns: a plotter returned by recon_plot initialization\n",
    "    :rtype: recon_plot\n",
    "\n",
    "    \"\"\"\n",
    "    target=np.array(unpackArray(row.vector,np.float16),dtype=np.float64)\n",
    "    if Title is None:\n",
    "        Title='%s / %d    %s'%(row['station'],row['year'],row['measurement'])\n",
    "    eigen_decomp=Eigen_decomp(range(1,366),target,Mean,v)\n",
    "    plotter=recon_plot(eigen_decomp,year_axis=True,fig=fig,ax=ax,interactive=interactive,Title=Title)\n",
    "    return plotter\n",
    "\n",
    "def plot_recon_grid(rows,column_n=4, row_n=3, figsize=(15,10)):\n",
    "    \"\"\"plot a grid of reconstruction plots\n",
    "\n",
    "    :param rows: Data rows (as extracted from the measurements data-frame\n",
    "    :param column_n: number of columns\n",
    "    :param row_n:  number of rows\n",
    "    :param figsize: Size of figure\n",
    "    :returns: None\n",
    "    :rtype: \n",
    "\n",
    "    \"\"\"\n",
    "    fig,axes=plt.subplots(row_n,column_n, sharex='col', sharey='row',figsize=figsize);\n",
    "    k=0\n",
    "    for i in range(row_n):\n",
    "        for j in range(column_n):\n",
    "            row=rows[k]\n",
    "            k+=1\n",
    "            #_title='%3.2f,r1=%3.2f,r2=%3.2f,r3=%3.2f'\\\n",
    "            #        %(row['res_mean'],row['res_1'],row['res_2'],row['res_3'])\n",
    "            #print i,j,_title,axes[i,j]\n",
    "            plot_decomp(row,Mean,v,fig=fig,ax=axes[i,j],interactive=False)\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "#### Different things to try\n",
    "The best/worst rows in terms of res_mean,res_1, res_2, res_3\n",
    "\n",
    "The rows with the highest lowest levels of coeff1, coeff2, coeff3, when the corresponding residue is small."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "df4=df3.filter(df3.res_2<0.4).sort(df3.coeff_2)\n",
    "rows=df4.take(12)\n",
    "df4.select('coeff_2','res_2').show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "plot_recon_grid(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "df3.sort?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df5=df3.filter(df3.res_2<0.4).sort(df3.coeff_2,ascending=False)\n",
    "rows=df5.take(12)\n",
    "df5.select('coeff_2','res_2').show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "plot_recon_grid(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Interactive plot of reconstruction\n",
    "\n",
    "Following is an interactive widget which lets you change the coefficients of the eigen-vectors to see the effect on the approximation.\n",
    "The initial state of the sliders (in the middle) corresponds to the optimal setting. You can zero a positive coefficient by moving the slider all the way down, zero a negative coefficient by moving it all the way up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "row=rows[0]\n",
    "target=np.array(unpackArray(row.vector,np.float16),dtype=np.float64)\n",
    "eigen_decomp=Eigen_decomp(None,target,Mean,v)\n",
    "total_var,residuals,reductions,coeff=eigen_decomp.compute_var_explained()\n",
    "res=residuals[1]\n",
    "print 'residual normalized norm  after mean:',res[0]\n",
    "print 'residual normalized norm  after mean + top eigs:',res[1:]\n",
    "\n",
    "plotter=recon_plot(eigen_decomp,year_axis=True,interactive=True)\n",
    "display(plotter.get_Interactive())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "### What is the distribution of the residuals and the coefficients?\n",
    "\n",
    "To answer this question we extract all of the values of `res_3` which is the residual variance after the Mean and the \n",
    "first two Eigen-vectors have been subtracted out. We rely here on the fact that `df3` is already sorted according to `res_3`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# A function for plotting the CDF of a given feature\n",
    "def plot_CDF(feat):\n",
    "    rows=df3.select(feat).sort(feat).collect()\n",
    "    vals=[r[feat] for r in rows]\n",
    "    P=np.arange(0,1,1./(len(vals)))\n",
    "    vals=[vals[0]]+vals\n",
    "    plot(vals,P)\n",
    "    title('cumulative distribution of '+feat)\n",
    "    ylabel('number of instances')\n",
    "    xlabel(feat)\n",
    "    grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_CDF('res_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "plot_CDF('coeff_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "filename=data_dir+'/decon_'+file_index+'_'+m+'.parquet'\n",
    "!rm -rf $filename\n",
    "df3.write.parquet(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "!du -sh $data_dir/*.parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "118px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "widgets": {
   "state": {
    "0d4726d074414304b7910c9bc9aee2a0": {
     "views": [
      {
       "cell_index": 31
      }
     ]
    },
    "9dfb4bbaf8664891a93b62da7476d8fe": {
     "views": [
      {
       "cell_index": 22
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
