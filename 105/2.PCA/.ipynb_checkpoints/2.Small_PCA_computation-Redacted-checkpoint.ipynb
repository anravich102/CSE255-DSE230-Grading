{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Computing PCA using RDDs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "###  PCA\n",
    "\n",
    "The vectors that we want to analyze have length, or dimension, of 365, corresponding to the number of \n",
    "days in a year.\n",
    "\n",
    "We want to perform [Principle component analysis (PCA)](https://en.wikipedia.org/wiki/Principal_component_analysis)\n",
    "on these vectors. There are two steps to this process:\n",
    "\n",
    "1. Computing the covariance matrix: this is a  simple computation. However, it takes a long time to compute and it benefits from using an RDD because it involves all of the input vectors.\n",
    "2. Computing the eigenvector decomposition. this is a more complex computation, but it takes a fraction of a second because the size to the covariance matrix is $365 \\times 365$, which is quite small. We do it on the head node usin `linalg`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Computing the covariance matrix\n",
    "Suppose that the data vectors are the column vectors denoted $x$ then the covariance matrix is defined to be\n",
    "$$\n",
    "E(x x^T)-E(x)E(x)^T\n",
    "$$\n",
    "\n",
    "Where $x x^T$ is the **outer product** of $x$ with itself.\n",
    "\n",
    "If the data that we have is $x_1,x_2,x_n$ then the estimates we use are:\n",
    "$$\n",
    "\\hat{E}(x x^T) = \\frac{1}{n} \\sum_{i=1}^n x_i x_i^T,\\;\\;\\;\\;\\;\n",
    "\\hat{E}(x) = \\frac{1}{n} \\sum_{i=1}^n x_i\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### `nan`s in arithmetic operations\n",
    "* We store all of the measurements as single `bytearray` in a single column. Instead of using 365 columns.\n",
    "* Why?\n",
    "  1. Because serializing and desirializing is faster that way.\n",
    "  1. Because numpy treats `nan` entries correctly:\n",
    "      * In `numpy.nansum` `5+nan=5` while in dataframes `5+nan=nan`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean of [1 1 1 2] = 1.25\n",
      "nanmean of [1 1 1 2] = 1.25\n",
      "mean of [  1.   1.  nan   2.] = nan\n",
      "nanmean of [  1.   1.  nan   2.] = 1.33333333333\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "X=np.array([1,1,1,2])\n",
    "print 'mean of',X,'=',np.mean(X)\n",
    "print 'nanmean of',X,'=',np.nanmean(X)\n",
    "X=np.array([1,1,np.NaN,2])\n",
    "print 'mean of',X,'=',np.mean(X)\n",
    "print 'nanmean of',X,'=',np.nanmean(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### When should you not use `np.nanmean` ?\n",
    "Using `n.nanmean` is equivalent to assuming that choice of which elements to remove is independent of the values of the elements. \n",