{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "## iPyLeaflet\n",
    "[ipyleaflet](https://github.com/ellisonbg/ipyleaflet) is a bridge between jupyter notebooks and the [leaflet](http://leafletjs.com/)  javascript library for drawing maps.\n",
    "\n",
    "ipyleaflet comes with a few examples notebooks (this notebook was derived from one) but very little documentation,\n",
    "for more documentation read the [Leaflet IPA](http://leafletjs.com/reference.html)\n",
    "\n",
    "For installation directions, see the README on [ipyleaflet](https://github.com/ellisonbg/ipyleaflet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "from ipyleaflet import (\n",
    "    Map,\n",
    "    Marker,\n",
    "    TileLayer, ImageOverlay,\n",
    "    Polyline, Polygon, Rectangle, Circle, CircleMarker,\n",
    "    GeoJSON,\n",
    "    DrawControl\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "## Visualizing the distribution of the observations\n",
    "\n",
    "## Load the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "import urllib\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sc = SparkContext.getOrCreate()\n",
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark import SparkContext\n",
    "#sc.stop()\n",
    "sc = SparkContext(master=\"local[3]\",pyFiles=['lib/numpy_pack.py','lib/computeStats.py'])\n",
    "\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import *\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./lib')\n",
    "\n",
    "import numpy as np\n",
    "from numpy_pack import packArray,unpackArray\n",
    "from computeStats import computeOverAllDist, STAT_Descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('keys from STAT=', ['TMIN', 'TOBS', 'TMAX', 'SNOW', 'SNWD', 'PRCP'])\n",
      "947\n",
      "+------------------+-------------------+------------------+---------+--------+--------+---------+-----------+-------------------+-------------------+-------------------+------------------+-----------+-----------+------+--------------------+------+\n",
      "|           coeff_1|            coeff_2|           coeff_3|elevation|   label|latitude|longitude|measurement|              res_1|              res_2|              res_3|          res_mean|    station|  total_var|undefs|              vector|  year|\n",
      "+------------------+-------------------+------------------+---------+--------+--------+---------+-----------+-------------------+-------------------+-------------------+------------------+-----------+-----------+------+--------------------+------+\n",
      "|3645.7765262509515|   828.805477559964|499.76581228215304|     44.2|BBBBBSBS| 43.9869|  -70.055|       SNWD|0.15320659652172913|0.10944404825099076|0.09353183959148387| 0.465196909805045|USC00172048| 3.374161E7|     0|[24 5F 90 60 90 6...|2008.0|\n",
      "|5270.7387954090555|-192.56472624550747| 267.4168387387765|    201.2|BBBBBSBS| 43.7833|   -71.65|       SNWD|0.09711077313180999|0.09590561244602128| 0.0935814365987118|0.5546395845964531|USC00276945|5.5475044E7|     0|[C0 5E C4 60 C4 6...|1982.0|\n",
      "+------------------+-------------------+------------------+---------+--------+--------+---------+-----------+-------------------+-------------------+-------------------+------------------+-----------+-----------+------+--------------------+------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Read the data frame from pickle file\n",
    "\n",
    "data_dir='../../Data/Weather'\n",
    "file_index='BBBBBSBS'\n",
    "meas='SNWD'\n",
    "\n",
    "from pickle import load\n",
    "\n",
    "#read statistics\n",
    "filename=data_dir+'/STAT_%s.pickle'%file_index\n",
    "STAT,STAT_Descriptions = load(open(filename,'rb'))\n",
    "print('keys from STAT=',STAT.keys())\n",
    "\n",
    "#!ls -ld $data_dir/*.parquet\n",
    "\n",
    "#read data\n",
    "filename=data_dir+'/decon_%s_%s.parquet'%(file_index,meas)\n",
    "\n",
    "df=sqlContext.read.parquet(filename)\n",
    "print(df.count())\n",
    "df.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT station, latitude,longitude,elevation,coeff_1 FROM weather\n",
      "+-----------+--------+---------+---------+------------------+\n",
      "|    station|latitude|longitude|elevation|           coeff_1|\n",
      "+-----------+--------+---------+---------+------------------+\n",
      "|USC00172048| 43.9869|  -70.055|     44.2|3645.7765262509515|\n",
      "|USC00276945| 43.7833|   -71.65|    201.2|5270.7387954090555|\n",
      "|USC00176011| 43.8792| -70.6328|    106.7|  2884.13188812732|\n",
      "|US1NHMR0025| 43.2115| -71.4143|    210.3|2328.6304627531117|\n",
      "+-----------+--------+---------+---------+------------------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#extract longitude and latitude for each station\n",
    "feature='coeff_1'\n",
    "sqlContext.registerDataFrameAsTable(df,'weather')\n",
    "Query=\"SELECT station, latitude,longitude,elevation,%s FROM weather\"%feature\n",
    "print(Query)\n",
    "df1 = sqlContext.sql(Query)\n",
    "df1.show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>elevation</th>\n",
       "      <th>count(station)</th>\n",
       "      <th>avg(coeff_1)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>CA008206500</td>\n",
       "      <td>43.833</td>\n",
       "      <td>-66.083</td>\n",
       "      <td>48.0</td>\n",
       "      <td>2</td>\n",
       "      <td>31.794827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>US1MECM0007</td>\n",
       "      <td>43.744</td>\n",
       "      <td>-70.489</td>\n",
       "      <td>44.8</td>\n",
       "      <td>1</td>\n",
       "      <td>2337.191984</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        station  latitude  longitude  elevation  count(station)  avg(coeff_1)\n",
       "68  CA008206500    43.833    -66.083       48.0               2     31.794827\n",
       "72  US1MECM0007    43.744    -70.489       44.8               1   2337.191984"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2=df1.groupby(['station','latitude','longitude','elevation']).agg({\"station\": \"count\", feature: \"mean\"})\n",
    "pdf=df2.toPandas()\n",
    "pdf.sort_values(by=['station'],inplace=True)\n",
    "pdf.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1381.63618461 3759.47071621\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Colormap BuYlRd is not recognized. Possible values are: Accent, Accent_r, Blues, Blues_r, BrBG, BrBG_r, BuGn, BuGn_r, BuPu, BuPu_r, CMRmap, CMRmap_r, Dark2, Dark2_r, GnBu, GnBu_r, Greens, Greens_r, Greys, Greys_r, OrRd, OrRd_r, Oranges, Oranges_r, PRGn, PRGn_r, Paired, Paired_r, Pastel1, Pastel1_r, Pastel2, Pastel2_r, PiYG, PiYG_r, PuBu, PuBuGn, PuBuGn_r, PuBu_r, PuOr, PuOr_r, PuRd, PuRd_r, Purples, Purples_r, RdBu, RdBu_r, RdGy, RdGy_r, RdPu, RdPu_r, RdYlBu, RdYlBu_r, RdYlGn, RdYlGn_r, Reds, Reds_r, Set1, Set1_r, Set2, Set2_r, Set3, Set3_r, Spectral, Spectral_r, Vega10, Vega10_r, Vega20, Vega20_r, Vega20b, Vega20b_r, Vega20c, Vega20c_r, Wistia, Wistia_r, YlGn, YlGnBu, YlGnBu_r, YlGn_r, YlOrBr, YlOrBr_r, YlOrRd, YlOrRd_r, afmhot, afmhot_r, autumn, autumn_r, binary, binary_r, bone, bone_r, brg, brg_r, bwr, bwr_r, cool, cool_r, coolwarm, coolwarm_r, copper, copper_r, cubehelix, cubehelix_r, flag, flag_r, gist_earth, gist_earth_r, gist_gray, gist_gray_r, gist_heat, gist_heat_r, gist_ncar, gist_ncar_r, gist_rainbow, gist_rainbow_r, gist_stern, gist_stern_r, gist_yarg, gist_yarg_r, gnuplot, gnuplot2, gnuplot2_r, gnuplot_r, gray, gray_r, hot, hot_r, hsv, hsv_r, inferno, inferno_r, jet, jet_r, magma, magma_r, nipy_spectral, nipy_spectral_r, ocean, ocean_r, pink, pink_r, plasma, plasma_r, prism, prism_r, rainbow, rainbow_r, seismic, seismic_r, spectral, spectral_r, spring, spring_r, summer, summer_r, tab10, tab10_r, tab20, tab20_r, tab20b, tab20b_r, tab20c, tab20c_r, terrain, terrain_r, viridis, viridis_r, winter, winter_r",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-bdfab4c35976>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_min\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_min\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mcm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_cmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'BuYlRd'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/rafaliang/anaconda/envs/py27/lib/python2.7/site-packages/matplotlib/cm.pyc\u001b[0m in \u001b[0;36mget_cmap\u001b[0;34m(name, lut)\u001b[0m\n\u001b[1;32m    171\u001b[0m         raise ValueError(\n\u001b[1;32m    172\u001b[0m             \u001b[0;34m\"Colormap %s is not recognized. Possible values are: %s\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m             % (name, ', '.join(sorted(cmap_d.keys()))))\n\u001b[0m\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Colormap BuYlRd is not recognized. Possible values are: Accent, Accent_r, Blues, Blues_r, BrBG, BrBG_r, BuGn, BuGn_r, BuPu, BuPu_r, CMRmap, CMRmap_r, Dark2, Dark2_r, GnBu, GnBu_r, Greens, Greens_r, Greys, Greys_r, OrRd, OrRd_r, Oranges, Oranges_r, PRGn, PRGn_r, Paired, Paired_r, Pastel1, Pastel1_r, Pastel2, Pastel2_r, PiYG, PiYG_r, PuBu, PuBuGn, PuBuGn_r, PuBu_r, PuOr, PuOr_r, PuRd, PuRd_r, Purples, Purples_r, RdBu, RdBu_r, RdGy, RdGy_r, RdPu, RdPu_r, RdYlBu, RdYlBu_r, RdYlGn, RdYlGn_r, Reds, Reds_r, Set1, Set1_r, Set2, Set2_r, Set3, Set3_r, Spectral, Spectral_r, Vega10, Vega10_r, Vega20, Vega20_r, Vega20b, Vega20b_r, Vega20c, Vega20c_r, Wistia, Wistia_r, YlGn, YlGnBu, YlGnBu_r, YlGn_r, YlOrBr, YlOrBr_r, YlOrRd, YlOrRd_r, afmhot, afmhot_r, autumn, autumn_r, binary, binary_r, bone, bone_r, brg, brg_r, bwr, bwr_r, cool, cool_r, coolwarm, coolwarm_r, copper, copper_r, cubehelix, cubehelix_r, flag, flag_r, gist_earth, gist_earth_r, gist_gray, gist_gray_r, gist_heat, gist_heat_r, gist_ncar, gist_ncar_r, gist_rainbow, gist_rainbow_r, gist_stern, gist_stern_r, gist_yarg, gist_yarg_r, gnuplot, gnuplot2, gnuplot2_r, gnuplot_r, gray, gray_r, hot, hot_r, hsv, hsv_r, inferno, inferno_r, jet, jet_r, magma, magma_r, nipy_spectral, nipy_spectral_r, ocean, ocean_r, pink, pink_r, plasma, plasma_r, prism, prism_r, rainbow, rainbow_r, seismic, seismic_r, spectral, spectral_r, spring, spring_r, summer, summer_r, tab10, tab10_r, tab20, tab20_r, tab20b, tab20b_r, tab20c, tab20c_r, terrain, terrain_r, viridis, viridis_r, winter, winter_r"
     ]
    }
   ],
   "source": [
    "#define a mapping from the range of the value to hex colors.\n",
    "from matplotlib.colors import rgb2hex\n",
    "_avg='avg(%s)'%feature\n",
    "_min=pdf[_avg].min()\n",
    "_max=pdf[_avg].max()\n",
    "_min,_max\n",
    "# _min = 24.1429\n",
    "# _max = 172.9380\n",
    "\n",
    "import pylab as plt\n",
    "cmap=plt.get_cmap('jet')\n",
    "def get_color(val):\n",
    "    x=(val-_min)/(_max-_min)\n",
    "    return(rgb2hex(cmap(x)[:3]))\n",
    "print _min, _max\n",
    "\n",
    "x = range(0,-int(round(_min))+int(round(_max)))\n",
    "y = range(int(round(_min)),int(round(_max)))\n",
    "cm = plt.cm.get_cmap('RdYlBu_r') \n",
    "plt.figure()\n",
    "plt.scatter(x, y,c=y, cmap = cm)\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "#get_color(1000.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "## Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#min_lat,max_lat,min_long,max_long = box = (42.1103, 42.6167, -72.6, -70.8)\n",
    "min_lat,max_lat,min_long,max_long = box = (42.6408, 44.0303, -71.65, -69.2622)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT station,vector FROM weather WHERE measurement='SNWD'\n",
      "+-----------+--------------------+\n",
      "|    station|              vector|\n",
      "+-----------+--------------------+\n",
      "|USC00172048|[24 5F 90 60 90 6...|\n",
      "|USC00276945|[C0 5E C4 60 C4 6...|\n",
      "|USC00176011|[C4 5C F4 5D F4 5...|\n",
      "|US1NHMR0025|[F0 57 C0 54 60 5...|\n",
      "|USC00176011|[2A 60 C2 61 8E 6...|\n",
      "+-----------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### get station and vector\n",
    "feat = \"'SNWD'\"\n",
    "sqlContext.registerDataFrameAsTable(df,'weather')\n",
    "#Query=\"SELECT station, latitude,longitude,elevation,%s FROM weather where station in (SELECT DISTINCT(station) FROM weather)\"%feature\n",
    "#Query=\"SELECT MIN(latitude),MAX(latitude),MIN(longitude),MAX(longitude) FROM weather WHERE station!='CA008206500'\"\n",
    "Query = \"SELECT station,vector FROM weather WHERE measurement=%s\"%feat\n",
    "print(Query)\n",
    "df3 = sqlContext.sql(Query)\n",
    "df3.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from numpy_pack import packArray,unpackArray\n",
    "df4 = df3.rdd.map(lambda row:[row['station'],np.nanmean(unpackArray(row['vector'],np.float16),dtype='float64')])\n",
    "total_snow_per_year=defaultdict(float)\n",
    "for row in df4.collect():\n",
    "    total_snow_per_year[row[0]] += row[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be17f85a22ae49cabb4d7beb6e27e936"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "center = [(min_lat+max_lat)/2, (min_long+max_long)/2]\n",
    "zoom = 9\n",
    "\n",
    "m = Map(default_tiles=TileLayer(opacity=1.0), center=center, zoom=zoom,\n",
    "            legend_name='snow depth')\n",
    "\n",
    "r = Rectangle(bounds=[[min_lat,min_long],[max_lat,max_long]], weight=5, fill_opacity=0.0)\n",
    "m += r\n",
    "\n",
    "# minSnow = 99999999\n",
    "# maxSnow = 0\n",
    "\n",
    "lat_margin=(max_lat-min_lat)/4\n",
    "long_margin=(max_long-min_long)/4\n",
    "circles = []\n",
    "for index,row in pdf.iterrows():\n",
    "    _lat=row['latitude']\n",
    "    _long=row['longitude']\n",
    "    _count=row['count(station)']\n",
    "    _coef=row[_avg]\n",
    "#     _snow=total_snow_per_year[row['station']]/_count\n",
    "#     if (_snow>maxSnow):\n",
    "#         maxSnow = _snow\n",
    "#     if (_snow<minSnow):\n",
    "#         minSnow = _snow\n",
    "    # taking sqrt of count so that the  area of the circle corresponds to the count\n",
    "    c = Circle(location=(_lat,_long), radius=int(300*np.sqrt(_count+0.0)), weight=1,\n",
    "            color='#F00', opacity=0.8, fill_opacity=0.4,\n",
    "            fill_color=get_color(_coef))\n",
    "    circles.append(c)\n",
    "    m.add_layer(c)\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "### excercises:\n",
    "* Add a legend that relates the colors to values.\n",
    "* Leaflet supports a variety of maps. See if you can get a topographical map as the background."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "pdf.plot.scatter(x='elevation',y='avg(coeff_1)');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RDD1=sc.parallelize([\"spark  basics\", \"spark big  data analysis\", \"spring\"]) \n",
    "RDD2=sc.parallelize([\"spark using pyspark\", \"big data\"])\n",
    " \n",
    "RDD1.subtract(RDD2).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a=np.array([ 432.,  610.,  610.,  610.,  686.,  660.,  660.,  635.,  610.,\n",
    "         610.,  610.,  610.,  610.,  711.,  686.,  686.,  686.,  635.,\n",
    "         635.,  660.,  635.,  610.,  610.,  838.,  813.,  813.,  813.,\n",
    "         787.,  787.,  787.,  787.,  787.,  787.,  787.,  762.,  762.,\n",
    "         787.,  762.,  762.,  762.,  889.,  838.,  838.,  838.,  813.,\n",
    "         787.,  787.,  762.,  762.,  762.,  864.,  813.,  813.,  813.,\n",
    "         813.,  787.,  787.,  787.,  787.,  787.,  864.,  838.,  787.,\n",
    "         864.,  864.,  838.,  914.,  914.,  940.,  965.,  914.,  864.,\n",
    "         813.,  787.,  787.,  787.,  787.,  762.,  737.,  737.,  787.,\n",
    "         737.,  711.,  711.,  686.,  660.,  635.,  610.,  610.,  584.,\n",
    "         533.,  533.,  508.,  508.,  508.,  483.,  762.,  483.,  457.,\n",
    "         457.,  432.,  483.,  381.,  381.,  381.,  330.,  305.,  229.,\n",
    "         203.,  102.,   51.,   51.,   51.,    0.,    0.,    0.,    0.,\n",
    "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
    "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
    "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
    "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
    "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
    "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
    "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
    "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
    "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
    "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
    "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
    "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
    "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
    "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
    "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
    "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
    "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
    "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
    "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
    "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
    "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
    "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
    "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
    "           0.,    0.,    0.,    0.,    0.,    0.,   25.,   25.,   25.,\n",
    "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
    "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
    "           0.,    0.,    0.,   25.,   25.,   25.,   51.,   51.,   25.,\n",
    "           0.,    0.,    0.,    0.,    0.],np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help (plt.colorbar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python [conda env:py27]",
   "language": "python",
   "name": "conda-env-py27-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "174px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
